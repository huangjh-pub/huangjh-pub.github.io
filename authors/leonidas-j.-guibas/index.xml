<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Leonidas J. Guibas | Jiahui Huang</title>
    <link>https://huangjh-pub.github.io/authors/leonidas-j.-guibas/</link>
      <atom:link href="https://huangjh-pub.github.io/authors/leonidas-j.-guibas/index.xml" rel="self" type="application/rss+xml" />
    <description>Leonidas J. Guibas</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 01 Aug 2023 23:15:32 -0700</lastBuildDate>
    <image>
      <url>https://huangjh-pub.github.io/media/icon_hu7092057554204590415.png</url>
      <title>Leonidas J. Guibas</title>
      <link>https://huangjh-pub.github.io/authors/leonidas-j.-guibas/</link>
    </image>
    
    <item>
      <title>DiffFacto: Controllable Part-Based 3D Point Cloud Generation with Cross Diffusion</title>
      <link>https://huangjh-pub.github.io/publication/diffacto/</link>
      <pubDate>Tue, 01 Aug 2023 23:15:32 -0700</pubDate>
      <guid>https://huangjh-pub.github.io/publication/diffacto/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multiway Non-rigid Point Cloud Registration via Learned Functional Map Synchronization</title>
      <link>https://huangjh-pub.github.io/publication/synorim/</link>
      <pubDate>Wed, 01 Dec 2021 21:59:40 +0800</pubDate>
      <guid>https://huangjh-pub.github.io/publication/synorim/</guid>
      <description>













&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /publication/synorim/teaser_hu6605768260645695503.webp 400w,
               /publication/synorim/teaser_hu15416954127689638820.webp 760w,
               /publication/synorim/teaser_hu6359287630242512699.webp 1200w&#34;
               src=&#34;https://huangjh-pub.github.io/publication/synorim/teaser_hu6605768260645695503.webp&#34;
               width=&#34;1024&#34;
               height=&#34;152&#34;
               loading=&#34;lazy&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;We present &lt;span style=&#34;color:Tomato&#34;&gt;&lt;strong&gt;Sy&lt;/strong&gt;&lt;/span&gt;&lt;span style=&#34;color:RoyalBlue&#34;&gt;&lt;strong&gt;NoRi&lt;/strong&gt;&lt;/span&gt;&lt;span style=&#34;color:MediumOrchid&#34;&gt;&lt;strong&gt;M&lt;/strong&gt;&lt;/span&gt;, a novel way to jointly register &lt;span style=&#34;color:MediumOrchid&#34;&gt;&lt;strong&gt;M&lt;/strong&gt;&lt;/span&gt;ultiple &lt;span style=&#34;color:RoyalBlue&#34;&gt;&lt;strong&gt;No&lt;/strong&gt;&lt;/span&gt;n-&lt;span style=&#34;color:RoyalBlue&#34;&gt;&lt;strong&gt;Ri&lt;/strong&gt;&lt;/span&gt;gid shapes by &lt;span style=&#34;color:Tomato&#34;&gt;&lt;strong&gt;Sy&lt;/strong&gt;&lt;/span&gt;nchronizing the maps that relate learned functions defined on the &lt;em&gt;point clouds&lt;/em&gt;.
Even though the ability to process non-rigid shapes is critical in various applications ranging from computer animation to 3D digitization, the literature still lacks a robust and flexible framework to match and align a collection of real, noisy scans observed under occlusions. Given a set of such point clouds, our method first computes the pairwise correspondences parameterized via functional maps.
We simultaneously learn potentially non-orthogonal basis functions to effectively regularize the deformations, while handling the occlusions in an elegant way. To maximally benefit from the multi-way information provided by the inferred pairwise deformation fields, we synchronize the pairwise functional maps into a cycle-consistent whole thanks to our novel and principled optimization formulation. We demonstrate via extensive experiments that our method achieves a state-of-the-art performance in registration accuracy, while being flexible and efficient as we handle both non-rigid and multi-body cases in a unified framework and avoid the costly optimization over point-wise permutations by the use of basis function maps.&lt;/p&gt;
&lt;h3 id=&#34;method&#34;&gt;Method&lt;/h3&gt;
&lt;p&gt;The &lt;strong&gt;input&lt;/strong&gt; to our method is a set of point clouds $\{ \mathbf{X}_k \in \mathbb{R}^{N_k \times 3} \}$ and the &lt;strong&gt;output&lt;/strong&gt; of our method contains all the pairwise per-point 3D flow vectors $\{ \mathbf{F}_{kl} \in \mathbb{R}^{N_k \times 3} \}$.
The flow vectors naturally induce the non-rigid warp field from $\mathbf{X}_k$ to $\mathbf{X}_l$ as $ \mathcal{W}_k (\mathbf{X}_k) =  \mathbf{X}_k + \mathbf{F}_{kl} $, optimally aligning the given point cloud pairs by deforming the source $\mathbf{X}_k$ onto the target $\mathbf{X}_l$.
For multiple input clouds we additionally encourage the cyclic consistency of the flow estimates, i.e.: $ \mathcal{W}_{k_1} \circ \mathcal{W}_{k_2} \circ ... \circ \mathcal{W}_{k_p} \approx \mathcal{I} $ for all cycles in the densely-connected graph formed by the input set.&lt;/p&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://huangjh-pub.github.io/publication/synorim/pipeline.svg&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;During training, our method is supervised in a pairwise fashion.
We first &lt;span class=&#34;hover&#34;&gt;&lt;span style=&#34;color:red&#34;&gt;①&lt;/span&gt; use a sparse-convolution-based neural network $\varphi_{\mathrm{desc}}$ (i.e., &lt;span style=&#34;background-color:#FFE4E8; border:dashed 1px; padding-bottom:0.2em&#34;&gt;$\mathfrak{g}_\mathrm{pd}$&lt;/span&gt;) to establish putative correspondences between each point cloud pair.&lt;/span&gt;
We then &lt;span class=&#34;hover&#34;&gt;&lt;span style=&#34;color:red&#34;&gt;②&lt;/span&gt; estimate a set of basis functions $\{ \mathbf{\Phi}_k \in \mathbb{R}^{N_k \times M} \}$ for each point cloud using another network $\varphi_{\mathrm{basis}}$.
By jointly modeling the correspondences and the bases in a robust way, the initial functional map $\mathbf{C}_{kl}^0$ is obtained before being refined with $\varphi_{\mathrm{refine}}$ that yields pairwise flow estimates. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;During test time with multiple inputs, we estimate the map set $\{\mathbf{C}_{kl}^0\}$ for all pairs.
&lt;span class=&#34;hover&#34;&gt;&lt;span style=&#34;color:red&#34;&gt;③&lt;/span&gt; The maps are subsequently synchronized to optimize for cycle consistency among the inputs. &lt;/span&gt;
Finally, &lt;span class=&#34;hover&#34;&gt;&lt;span style=&#34;color:red&#34;&gt;④&lt;/span&gt; 3D flows are estimated from the optimized functional maps $\{\mathbf{C}_{kl}^\star\}$ as our final output, using the same procedure as done in the pairwise setting.&lt;/span&gt;
The registered point cloud is a fusion of all initial point clouds warped by the estimated flows.
For more details, please read our technical report.&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;Some demonstrative registration results are shown below, all rendered as raw point clouds.
For each animation the points from all other sources are warped to the current view as target.
We use datasets from &lt;a href=&#34;https://cape.is.tue.mpg.de/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CAPE&lt;/a&gt;, &lt;a href=&#34;https://github.com/rabbityl/DeformingThings4D&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeformingThings4D&lt;/a&gt;, &lt;a href=&#34;https://github.com/AljazBozic/DeepDeform&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeepDeform&lt;/a&gt;, and &lt;a href=&#34;https://sapien.ucsd.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAPIEN&lt;/a&gt;.&lt;/p&gt;
&lt;!-- Originally I use h5 to wrap it, but it turns out to be unnecessary --&gt;
&lt;div class=&#39;three-cols-video&#39;&gt;









  





&lt;video autoplay loop  &gt;
  &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/a1.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt; 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 &lt;video autoplay loop  &gt;
   &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/h1.mp4&#34; type=&#34;video/mp4&#34;&gt;
 &lt;/video&gt; 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 &lt;video autoplay loop  &gt;
   &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/a2.mp4&#34; type=&#34;video/mp4&#34;&gt;
 &lt;/video&gt; 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 &lt;video autoplay loop  &gt;
   &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/h2.mp4&#34; type=&#34;video/mp4&#34;&gt;
 &lt;/video&gt; 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 &lt;video autoplay loop  &gt;
   &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/a3.mp4&#34; type=&#34;video/mp4&#34;&gt;
 &lt;/video&gt; 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 &lt;video autoplay loop  &gt;
   &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/h3.mp4&#34; type=&#34;video/mp4&#34;&gt;
 &lt;/video&gt;









  





&lt;video autoplay loop  &gt;
  &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/s1.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt; 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 &lt;video autoplay loop  &gt;
   &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/s2.mp4&#34; type=&#34;video/mp4&#34;&gt;
 &lt;/video&gt; 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 &lt;video autoplay loop  &gt;
   &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/s3.mp4&#34; type=&#34;video/mp4&#34;&gt;
 &lt;/video&gt;









  





&lt;video autoplay loop  &gt;
  &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/hp1.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt; 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 &lt;video autoplay loop  &gt;
   &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/hp2.mp4&#34; type=&#34;video/mp4&#34;&gt;
 &lt;/video&gt; 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 &lt;video autoplay loop  &gt;
   &lt;source src=&#34;https://huangjh-pub.github.io/publication/synorim/videos/hp3.mp4&#34; type=&#34;video/mp4&#34;&gt;
 &lt;/video&gt;
&lt;/div&gt;
&lt;!-- Make video autoplay. --&gt;
&lt;script&gt;
document.addEventListener(&#34;DOMContentLoaded&#34;, (function() {
  $(&#39;video&#39;).each(function(i, obj) {
    obj.muted = true;
    obj.play();
  });
}));
&lt;/script&gt;














&lt;figure  id=&#34;figure-dynamic-reconstruction-result-the-rgb-images-are-just-for-references&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Dynamic reconstruction result. The RGB images are just for references.&#34; srcset=&#34;
               /publication/synorim/recon_hu377666660400572581.webp 400w,
               /publication/synorim/recon_hu6777402551520326354.webp 760w,
               /publication/synorim/recon_hu752709778436055995.webp 1200w&#34;
               src=&#34;https://huangjh-pub.github.io/publication/synorim/recon_hu377666660400572581.webp&#34;
               width=&#34;760&#34;
               height=&#34;235&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Dynamic reconstruction result. The RGB images are just for references.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;We also provide extensive quantitative experiments and ablations in our main paper.
Our results on FAUST online challenge can also be viewed &lt;a href=&#34;http://faust.is.tue.mpg.de/challenge/Intra-subject_challenge?challenge_id=2&amp;amp;sort=3&amp;amp;subchallenge_id=2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;dataset&#34;&gt;Dataset&lt;/h3&gt;
&lt;p&gt;Our dataset is heavily based on published datasets. Although our modification is license-free, the original data providers may require you to accept different terms &amp;amp; conditions before being allowed to use them.
Be sure to double-check that before downloading.
If you find any legal issues, please let us know immediately.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;# Train&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;# Validation&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;# Test&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Origin&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Terms of Use&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Download Link&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;MPC-CAPE&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;3015&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;798&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;209&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://cape.is.tue.mpg.de/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CAPE&lt;/a&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://cape.is.tue.mpg.de/license.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1der12IAm_1o_M92nj71r0HpfxmBCaQmc/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data (11.2G)&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;MPC-DT4D&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;3907&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;1701&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;1299&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://github.com/rabbityl/DeformingThings4D&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeformingThings4D&lt;/a&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSckMLPBO8HB8gJsIXFQHtYVQaTPTdd-rZQzyr9LIIkHA515Sg/viewform&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1r9VFHIZcatSej6guY_hGoGjrNqbgazAz/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data (20.6G)&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;MPC-DD&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;1754&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;200&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;267&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://github.com/AljazBozic/DeepDeform&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeepDeform&lt;/a&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSeQ1hkCmmTiib-oQM9s21y3Tz9ojiI2zB8vZSqTZjT2DiRZ0g/viewform&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/1ykFSe9TI9kZ-RozZw874YHDiO1cLRCgc/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data (2.4G)&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;MPC-SAPIEN&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;530&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;88&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;266&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://sapien.ucsd.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAPIEN&lt;/a&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://sapien.ucsd.edu/about#term&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;&lt;a href=&#34;https://drive.google.com/file/d/13yMOoFmUV2Ca9j0tm_CD0nd1BGx1T8Jx/view?usp=sharing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data (1.3G)&lt;/a&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;!-- This will fix the table. --&gt;
&lt;script&gt;
document.addEventListener(&#34;DOMContentLoaded&#34;, (function() {
    $(&#39;table&#39;).addClass(&#39;table table-hover&#39;);
}));
&lt;/script&gt;
&lt;h3 id=&#34;citation&#34;&gt;Citation&lt;/h3&gt;
&lt;p&gt;If you find our work interesting, please consider citing us:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@article{huang2021multiway,
  title={Multiway Non-rigid Point Cloud Registration via Learned Functional Map Synchronization},
  author={Huang, Jiahui and Birdal, Tolga and Gojcic, Zan and Guibas, Leonidas J and Hu, Shi-Min},
  journal={arXiv preprint arXiv:2111.12878},
  year={2021}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h3&gt;
&lt;p&gt;We thank all the reviewers for their thoughtful comments and constructive suggestions.
This paper was supported by National Key R&amp;amp;D Program of China (project No. 2021ZD0112902), a Vannevar Bush faculty fellowship, ARL grant W911NF2120104, NSF grant IIS-1763268, and a gift from the Autodesk Corporation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MultiBodySync: Multi-Body Segmentation and Motion Estimation via 3D Scan Synchronization</title>
      <link>https://huangjh-pub.github.io/publication/multibodysync/</link>
      <pubDate>Mon, 01 Mar 2021 21:59:40 +0800</pubDate>
      <guid>https://huangjh-pub.github.io/publication/multibodysync/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DeepSpline: Data-Driven Reconstruction of Parametric Curves and Surfaces</title>
      <link>https://huangjh-pub.github.io/publication/deepspline/</link>
      <pubDate>Thu, 10 Jan 2019 22:01:07 +0800</pubDate>
      <guid>https://huangjh-pub.github.io/publication/deepspline/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DeepPrimitive: Image decomposition by layered primitive detection</title>
      <link>https://huangjh-pub.github.io/publication/deepprimitive/</link>
      <pubDate>Sun, 23 Dec 2018 23:15:32 -0700</pubDate>
      <guid>https://huangjh-pub.github.io/publication/deepprimitive/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
